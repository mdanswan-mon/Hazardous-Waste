{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lib.WebScrapping.CorpusScraper import *\n",
    "from Lib.TextAnalytics.Methods import *\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "webpages = get_tag_corpus([\"hazard\", \"battery\", \"marine\"], pages=1, methods=['Scholar'], from_year=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lib.PreProcessing.General import *\n",
    "corpus = [remove_stop_words(webpage.textual_content, 'Resources/stop-words.txt') for webpage in webpages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in corpus:\n",
    "    print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_tfidf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = result[1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_results = [csr_matrix.nonzero() for csr_matrix in result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_result_importance = list()\n",
    "for i, non_zero_result in enumerate(non_zero_results):\n",
    "    temp = list()\n",
    "    for (row, col) in zip(*non_zero_result):\n",
    "        temp.append(((row, col), result[0][i][row, col]))\n",
    "    temp.sort(key=lambda a: a[1], reverse=True)\n",
    "    non_zero_result_importance.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero = np.empty((len(features), len(webpages)), dtype=float)\n",
    "for idx, non_zero_result in enumerate(non_zero_result_importance):\n",
    "    for ((row, col), importance) in non_zero_result:\n",
    "        non_zero[col, idx] = importance\n",
    "non_zero = np.nan_to_num(non_zero, posinf=1, neginf=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(non_zero, index=features, columns=[webpage.title for webpage in webpages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webpage in webpages:\n",
    "    print(webpage.title, webpage.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "top_keywords = df.loc[(df > threshold).any(axis=1), (df > threshold).any()]\n",
    "top_keywords\n",
    "#top_keywords.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('HWaste')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bccd11027b6ad3402a27fd87d189f6132d31cf2fc498fa1869dc23f1ec9f10db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
